---
layout: page
title: Brando Miranda
---

![me](/images/me_rains_suit.jpg)

- [My Google Scholar](https://scholar.google.com/citations?user=_NQJoBkAAAAJ&hl=en)
- [Stanford Profile](https://profiles.stanford.edu/brando-miranda?releaseVersion=9.9.0)
- [Twitter](https://twitter.com/BrandoHablando)
- [Linkedin](https://www.linkedin.com/in/brando-miranda-40821046/)
- [MIT and CBMM Profile](https://cbmm.mit.edu/about/people/miranda)
- [All social media - Professional and Personal](https://linktr.ee/ultimate_brando9)
- brando9 {at} stanford DoT Edu

<!-- - [(Maybe outdated) CV](/professional_documents/Brando_Miranda_long_CV.pdf) -->
<!-- Department of Computer Science
Gates Computer Science Building
353 Jane Stanford Way
Stanford, CA 94305 -->

-----

<!-- https://chatgpt.com/share/34e27219-4ed4-4387-a2e9-ab06ef433409 -->

# Bio #

Brando Miranda is currently a Computer Science AI/ML Ph.D. student at [Stanford University ](https://stanford.edu)under the supervision of [Professor Sanmi Koyejo](https://cs.stanford.edu/~sanmi/index.html) in the [Stanford Trustworthy AI Research (STAIR) group.](https://cs.stanford.edu/~sanmi/index.html) 
Previously, Miranda was a graduate researcher at [University of Illinois Urbana-Champaign](https://illinois.edu/), 
a Research Assistant at the Massachusetts Institute of Technology (MIT)’s Center for Brain Minds and Machines (CBMM), and a graduate student at MIT.
Miranda's research interests focuses in data-centric machine learning for [Frontier Models (FMs)](https://openai.com/index/frontier-model-forum/), [Transformative Artificial Intelligence (TAI)](https://forum.effectivealtruism.org/topics/transformative-artificial-intelligence), and machine learning for mathematics and verified code. 
Miranda earned his Master of Engineering in Electrical Engineering and Computer Science at MIT, conducting research on Deep Learning Theory under the guidance of [Professor Tomaso Poggio](https://mcgovern.mit.edu/profile/tomaso-poggio/).
Miranda has been the recipient of several awards; including the presitgious 
[NeurIPS Outstanding Main Track Paper Award (top 0.4% and only 2 papers selected)](https://blog.neurips.cc/2023/12/11/announcing-the-neurips-2023-paper-awards/),
the [Most Cited Paper Certificate awarded by International Journal of Automation & Computing (IJAC)](/professional_documents/Why_and_When_Can_Deep_but_Not_Shallow_networks_Avoid_the_Curse_of_Dimensionality_A_Review.jpg),
two Honorable Mention with the Ford Foundation Fellowship,
Computer Science Excellence Saburo Muroga Endowed Fellow, 
Stanford School of Engineering fellowship, and is currently an EDGE Scholar at Stanford University.
Miranda is more than a researcher: he is an innovator, a communicator, and deeply passionate about the future.
Therefore, he collaborated and worked as a Machine Learning advisor at the AI start up [Morph Labs](https://morph.so/blog/the-personal-ai-proof-engineer/).
He was a key contributor to the [Morph Prover,](https://huggingface.co/morph-labs/morph-prover-v0-7b) a frontier model for mathematics and verified code in [Lean 4](https://leanprover-community.github.io/), and [Moogle.ai,](https://www.moogle.ai/) a search engine for verified code in Lean 4.
Aligned with his passion for innovation and start ups, he has also advised [Wise](https://wise-sales.com/about/), a Stanford based startup focused on transforming sales performance with AI. 

<!-- https://www.forbes.com.mx/la-revolucion-digital-en-america-latina-desbloqueando-el-potencial-de-la-region/ -->

---

# Shorter Bio #
Brando Miranda is currently a Computer Science AI/ML Ph.D. student at [Stanford University ](https://stanford.edu)under the supervision of [Professor Sanmi Koyejo](https://cs.stanford.edu/~sanmi/index.html) in the [Stanford Trustworthy AI Research (STAIR) group.](https://cs.stanford.edu/~sanmi/index.html)
Miranda's research interests focuses in data-centric machine learning for [Frontier Models (FMs)](https://openai.com/index/frontier-model-forum/), [Transformative Artificial Intelligence (TAI)](https://forum.effectivealtruism.org/topics/transformative-artificial-intelligence), and machine learning for mathematics and verified code. 
Miranda has been the recipient of several awards; including the presitgious 
[NeurIPS Outstanding Main Track Paper Award (top 0.4% and only 2 papers selected).](https://blog.neurips.cc/2023/12/11/announcing-the-neurips-2023-paper-awards/)
Miranda is more than a researcher: he is an innovator, a communicator, and deeply passionate about the future.
Therefore, he collaborated and worked as a Machine Learning advisor at the AI start up [Morph Labs](https://morph.so/blog/the-personal-ai-proof-engineer/) where he was a key contributor to the [Morph Prover,](https://huggingface.co/morph-labs/morph-prover-v0-7b) a frontier model for mathematics and verified code, and [Moogle.ai,](https://www.moogle.ai/) a search engine for verified code.
In addition, he advised [Wise](https://wise-sales.com/about/), a Stanford based startup focused on transforming sales performance with AI.

<!-- 
Sure! Mira todo anda en mi LinkedIn o personal website. 

Mira las paginas:
Wise-sales.com 
Wise-meetings.com 

Este es un forbes article que habla de Wise Meetings:
https://www.forbes.com.mx/la-revolucion-digital-en-america-latina-desbloqueando-el-potencial-de-la-region/

Aqui el link donde hablo de ellas en mi personal website:
https://www.santiagocampo.com/wise-meetings 

Ya somos como 50 en el equipo entre ambos equipos.
 -->

[//]: # (https://cs.stanford.edu/~sanmi/preparation.html  working with me, TODO: )

[//]: # (Our Culture:
[//]: # (  
[//]: # (Our lab has a high technical bar, including a coding interview for all applicants. We constantly push each other to improve through continuous, regular feedback. We take mentorship seriously and are committed to students' success beyond their time in our lab. As a member of our lab, you will be working alongside prior USACO and IMO participants. We have exceedingly high expectations of all collaborators and do not tolerate mediocrity. look for his lab page Sebastian Thrun's lab.)
[//]: # (someone from caltech or something like htat?)

<!-- ![me](/images/me_rains_suit.jpg){:class="img-responsive"} -->
<!-- ![me](/images/me_rains_suit.jpg) -->

---

# Selected Publications [ [Full List] ](https://scholar.google.com/citations?user=_NQJoBkAAAAJ&hl=en)

[//]: # (Note: * denotes equal contribution.)


Putnam-AXIOM: A Functional & Static Benchmark for Measuring Higher Level Mathematical Reasoning in LLMs
*Aryan Gulati, Brando Miranda, Eric Chen, Emily Xia, Kai Fronsdal, Bruno de Moraes Dumont, Sanmi Koyejo.*
<!-- [**[arxiv]**](TODO) -->
[**[International Conference on Machine Learning (ICML)]**](https://icml.cc/virtual/2025/poster/44232)
[**[NeurIPS MATH-AI Workshop 2024]**]](https://neurips.cc/virtual/2024/98507) 
<!-- in case neurips link goes down for math-ai: https://openreview.net/forum?id=YXnwlZe0yf -->

Why Has Predicting Downstream Capabilities of Frontier AI Models with Scale Remained Elusive?
*Rylan Schaeffer, Hailey Schoelkopf, Brando Miranda, Gabriel Mukobi, Varun Madan, Adam Ibrahim, Herbie Bradley, Stella Biderman, Sanmi Koyejo.* 
ICML Outstanding Paper TiFA Trustworthy Multi-modal Foundation Models and AI Agents (TiFA) Workshop award.
[**\[arxiv\]**](https://arxiv.org/pdf/2406.04391)[**[ICML Award]**]((/professional_documents/tifa_award_elusive.png))

Are Emergent Abilities of Large Language Models a Mirage?
*Rylan Schaeffer, Brando Miranda, Sanmi Koyejo.*
[**[NeurIPS Outstanding Main Track Paper Award 2023 & NeurIPS Oral]**](https://blog.neurips.cc/2023/12/11/announcing-the-neurips-2023-paper-awards/)
[**[OpenReview]**](https://openreview.net/forum?id=ITw9edRDlD) 
[**[Stanford IEEE Invited Talk 2023]**](https://www.youtube.com/live/ypKwNrmuuPM?si=G8mfIdPaAFx82Jcl)
<!-- [**[NeurIPS Oral]**](https://neurips.cc/virtual/2023/poster/72117) -->

<!-- Are Emergent Abilities of Large Language Models a Mirage?
*Rylan Schaeffer, Brando Miranda, Sanmi Koyejo.*
**Preprint & ICML Challenges in Deployable Generative AI Workshop 2023.**
[**[arXiv]**](https://arxiv.org/abs/2304.15004)  -->

Morph Prover v0 7b: The 1st Frontier Model for the Lean 4 Formal Verification Programming Language
[**[blog]**](https://morph.so/blog/the-personal-ai-proof-engineer/)
[**[HF Model Card]**](https://huggingface.co/morph-labs/morph-prover-v0-7b)

Is Pre-training Truly Better Than Meta-Learning?
Brando Miranda, Patrick Yu, Saumya Goyal, Yu-Xiong Wang, Sanmi Koyejo.
**ICML Data-Centric Machine Learning Workshop 2023.**
[**[Poster]**](https://docs.google.com/presentation/d/127Kmbi93dZOtGFnTEgyAvAWv4sX-RRPlEZh8p4zuUOw/edit?usp=sharing)
[**[arxiv]**](https://arxiv.org/abs/2306.13841)
[**[ICML PDF]**](https://dmlr.ai/assets/accepted-papers/117/CameraReady/MAML_vs_PT___NeurIPS__ICML_2023__Draft_2_.pdf)
[**[Code Coming Soon]**]()

Beyond Scale: the Diversity Coefficient as a Data Quality Metric Demonstrates LLMs are Pre-trained on Formally Diverse Data.
*Alycia Lee\*, Brando Miranda\*, Patrick Yu, and Oluwasanmi Koyejo.*
**ICML Data-Centric Machine Learning Workshop 2023 & ICML Challenges in Deployable Generative AI Workshop 2023.**
[**[Poster]**](https://docs.google.com/presentation/d/1QF-S8URtOMWxsdaam_rVCWsotEC3CDsvQoNnboQ1CEI/edit?usp=sharing)
[**[arxiv]**](https://arxiv.org/abs/2306.13840)
[**[ICML PDF]**](https://dmlr.ai/assets/accepted-papers/113/CameraReady/ICML_2023_DMLR_Workshop__Diversity_Coefficient___LLMs__8pg_.pdf)
[**[Code]**](https://github.com/alycialee/beyond-scale-language-data-diversity)

[//]: # ([**[Stanford Data Science Poster]**]&#40;https://docs.google.com/presentation/d/1W4biGEKO7jGOviClEtkqM6sscsth1mK9/edit?usp=sharing&ouid=111989168652781065814&rtpof=true&sd=true&#41;)
[//]: # ([**[Short 8 page paper]**]&#40;professional_documents/ICML_2023_DeployGenAI_Workshop__Diversity_Coefficient___LLMs__8pg_.pdf&#41;)
[//]: # ([**[Short 6 page paper]**]&#40;professional_documents/ICML_2023_DeployGenAI_Workshop__Diversity_Coefficient___LLMs__6pg_.pdf&#41;)
[//]: # (**Generative AI and Foundation Models Workshop 2023 - SAIL &#40;Stanford Artificial Intelligence Laboratory&#41;.**)
[//]: # ([**2023 Stanford Data Science Conference.**]&#40;https://datascience.stanford.edu/2023-stanford-data-science-conference&#41;)
[//]: # ([**[SAIL Poster]**]&#40;professional_documents/SAIL_2023_Poster.pdf&#41;)

[The Curse of Low Task Diversity: On the Failure of Transfer Learning to Outperform MAML and Their Empirical Equivalence.](https://openreview.net/forum?id=Z75fwzPdty)
*Brando Miranda, Patrick Yu, Yu-Xiong Wang, Oluwasanmi Koyejo.*
**NeurIPS Meta-Learning Workshop 2022, Contributed Talk.**
[**[arXiv]**](https://arxiv.org/abs/2208.01545) 
[**[Poster]**](professional_documents/Poster_Low_Diversity____NeurIPS_WS_2022__Draft_2_.pdf)
[**[5 minute video]**](https://youtu.be/mM5vllz1hPg)
[**[15 minute video Contributed Talk]**](https://slideslive.com/38996684/the-curse-of-low-task-diversity-on-the-failure-of-transfer-learning-to-outperform-maml-and-their-empirical-equivalence?ref=search-presentations-low+diversity)
[**[Code Coming Soon]**]()

[//]: # ([**[PDF]**]&#40;https://openreview.net/forum?id=Z75fwzPdty&#41;)
[//]: # ([**[15 minute video Contributed Talk, pre-recording]**]&#40;https://youtu.be/3LfTWHIgmvM&#41;)
[//]: # ([**[Code, contact me for now, coming soon I hope!]**]&#40;&#41;)
[//]: # (5 min video from neurips)
[//]: # (https://slideslive.com/38994633/the-curse-of-low-task-diversity-on-the-failure-of-transfer-learning-to-outperform-maml-and-their-empirical-equivalence?ref=search-presentations-low+diversity)

[Does MAML Only Work via Feature Re-use? A Data Centric Perspective](https://arxiv.org/abs/2112.13137)
*Brando Miranda, Yu-Xiong Wang, Oluwasanmi Koyejo.*
**Preprint, Best research project award for graduate course CS 598 “Learning to Learn” by professor Y. Wang UIUC (December 2020).**
[**[arXiv]**](https://arxiv.org/abs/2112.13137)
[**[5 minute video]**](https://youtu.be/WyG6bwGnbGc)

[//]: # ([**[PDF]**]&#40;https://www.ideals.illinois.edu/handle/2142/109139&#41;)

[Weight and Batch Normalization implement Classical Generalization Bounds.](https://sites.google.com/view/icml2019-generalization/accepted-papers)
*Tomaso Poggio Andrzej Banburski, Qianli Liao, Brando Miranda, Lorenzo Rosasco, Jack Hidary.*
**ICML Workshop 2019**
[**[PDF]**](https://sites.google.com/view/icml2019-generalization/accepted-papers)

[//]: # ([**[PDF]**]&#40;/professional_documents/ICML2019_paper_53.pdf&#41;)

[High-performance and scalable on-chip digital Fourier transform spectroscopy.](https://www.nature.com/articles/s41467-018-06773-2)
*Derek M Kita, Brando Miranda, David Favela, David Bono, Jérôme Michon, Hongtao Lin, Tian Gu, Juejun Hu.*
**Nature Communications 2018.**
[**[PDF]**](https://www.nature.com/articles/s41467-018-06773-2)

[Why and when can deep-but not shallow-networks avoid the curse of dimensionality: a review.](https://link.springer.com/article/10.1007/s11633-017-1054-2)
*Tomaso Poggio, Hrushikesh Mhaskar, Lorenzo Rosasco, Brando Miranda, Qianli Liao.*
**International Journal of Automation and Computing 2017, Most Cited Paper Certificate awarded by International Journal of Automation & Computing (IJAC).**
[**[PDF]**](https://link.springer.com/article/10.1007/s11633-017-1054-2)
[**[Award]**](/professional_documents/Why_and_When_Can_Deep_but_Not_Shallow_networks_Avoid_the_Curse_of_Dimensionality_A_Review.jpg)

---

# Media Coverage

Below are selected links showcasing media coverage of some of my work:

[**Economic Report to the White House Washington**: our work was cited in the 2024 Economic Report of the president. Direct quote: "The Report presents an overview of the nation’s economic progress and makes the case for the Biden-Harris Administration’s economic policy priorities.](https://www.whitehouse.gov/cea/written-materials/2024/03/21/the-2024-economic-report-of-the-president/)[**[Report]**](https://www.whitehouse.gov/wp-content/uploads/2024/03/ERP-2024-CHAPTER-7.pdf)[**[ScreenShot]**](images/white_house_labor_substitute_huam_rs_bm_sk.png)
<!-- [**[CopyReport]**](non_personal_documents/white house report schaeffer miranda koyejo cited.pdf) -->

[**The New York Times**: Silicon Valley Confronts the Idea That the ‘Singularity’ Is Here.](https://www.nytimes.com/2023/06/11/technology/silicon-valley-confronts-the-idea-that-the-singularity-is-here.html)

[**Y Combinator News**: Are emergent abilities of large language models a mirage?](https://news.ycombinator.com/item?id=35768824)

[**Quanta Magazine**: How Quickly Do Large Language Models Learn Unexpected Skills? - A new study suggests that so-called emergent abilities actually develop gradually and predictably, depending on how you measure them.](https://www.quantamagazine.org/how-quickly-do-large-language-models-learn-unexpected-skills-20240213/)

[**Stanford's Institute for Human-Centered Artificial Intelligence (HAI)**: AI’s Ostensible Emergent Abilities Are a Mirage](https://hai.stanford.edu/news/ais-ostensible-emergent-abilities-are-mirage)

[**Forbes**: AI ‘Emergent Abilities’ Are A Mirage, Says AI Researcher](https://www.forbes.com/sites/andreamorris/2023/05/09/ai-emergent-abilities-are-a-mirage-says-ai-researcher/?sh=1ec9b33f283f)

[**Andrew Ng** endorsed our paper & believes it is evidence that AGI won't come discontinuously, but instead, will come smoothly and predictably](https://x.com/AndrewYNg/status/1766554536192446957?s=20)

This work was also covered by: [Vice, Medium, Hackwernews, NeurIPS blog, Reddit, and more](https://www.google.com/search?q=are+emergent+abilities+of+large+language+models+a+mirage&sca_esv=601452934&rlz=1C5CHFA_enUS741US741&sxsrf=ACQVn0-c2GdoTGcENwUnRQq9OL9o9oMnRw%3A1706215019783&ei=a8ayZdCpL_DnkPIP4pu2yA4&oq=are+emergent+abilities+of+large++a+mirage&gs_lp=Egxnd3Mtd2l6LXNlcnAiKWFyZSBlbWVyZ2VudCBhYmlsaXRpZXMgb2YgbGFyZ2UgIGEgbWlyYWdlKgIIADIGEAAYBxgeMgYQABgHGB4yBhAAGAcYHjIGEAAYBxgeSMc-UKcEWNw3cAB4AZABAJgBWqABqAmqAQIxN7gBA8gBAPgBAcICBBAAGEfCAgQQIxgnwgIKECMYgAQYigUYJ8ICFxAuGIAEGIoFGJECGLEDGIMBGMcBGNEDwgIKEAAYgAQYigUYQ8ICBRAAGIAEwgILEAAYgAQYsQMYgwHCAg4QLhiABBiKBRixAxiDAcICERAuGIAEGLEDGIMBGMcBGNEDwgIREC4YgAQYigUYkQIYsQMYgwHCAgsQLhiABBiKBRiRAsICCxAAGIAEGIoFGJECwgIOEAAYgAQYigUYsQMYgwHCAggQABiABBixA-IDBBgAIEGIBgGQBgg&sclient=gws-wiz-serp#ip=1), courtesy of Google search. 

---

# Awards

- [ICML Outstanding Paper TiFA Trustworthy Multi-modal Foundation Models and AI Agents (TiFA) Workshop (July 2024)](/professional_documents/tifa_award_elusive.png)
- [NeurIPS Outstanding Main Track Paper Award, (December 11 2023) (top 0.4% and only 2 papers selected)](https://blog.neurips.cc/2023/12/11/announcing-the-neurips-2023-paper-awards/)
- EDGE Scholar, Stanford University (September 2022)
- Stanford School of Engineering fellowship, Stanford University (September 2022)
- Best Research Project Award for Graduate Course CS 598 "Learning to Learn" by professor Y. Wang (December 2020).
- HSF (Hispanic Scholarship Fund) Scholar (2020)
- Honorable Mention, Ford Foundation Fellowship (2020, 2021)
- [Most Cited Paper Certificate awarded by International Journal of Automation & Computing (IJAC), (December 2019)](/professional_documents/Why_and_When_Can_Deep_but_Not_Shallow_networks_Avoid_the_Curse_of_Dimensionality_A_Review.jpg)
- Computer Science Excellence Saburo Muroga Endowed Fellow, (2019-2020)
- Sloan Scholar, Alfred P. Sloan Foundations Minority Ph.D. (MPHD) Program, awarded in (2018-2019)
- Grainger Engineering SURGE Fellowship, awarded in (2018-2019)
- Chopper Trading, LLC, Best Strategy Report award, MIT Battle Code AI competition (2013)
- MIT Mitchell B. Kaufman Memorial Scholarship (2012-2013, 2013-2014)
- MIT Eugene and Margaret (HM) McDermott Scholarship (2012-2013, 2013-2014)
- High Achievement Prize Award, Greengates School (2007, 2008, 2009, 2010), similar to Valedictorian
- Best all round student award, Greengates School (2010)
- Achievement Prize award, Greengates School (2006)
- Certificate for Progress award, Greengates School (2005)
